# Truong et al., 2021

* ML-based service providers not only confront with difficulties in collecting and managing data across heterogeneous sources, but also challenges of complying with rigorous data protection regulation such as GDPR.
* Traditional ML approaches are continuously standing the risks of data leakage, misuse and abuse.
* FL is an emerged prospective solution, but it is not sufficient for privacy-guarantee as model parameters exchange among participants which can be exploitable.
* FL by its default nature stays in GDPR regulatory data protection framework. But because intermediates, such as locally trained ML model parameters, gradients and weights are still highly capable of giving away sensitive information of data due to certain exploits, it could still lead to infringements of GDPR, making current FL still not cope with GDPR 100%.
* FL system, eventually as a black-box complex ML, transparency will be an issue while the service providers and DPAs are trying to comprehend or inspect hidden operations inside the system
